{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from numpy.random import seed\n",
    "seed(1337)\n",
    "#from tensorflow import set_random_seed\n",
    "#set_random_seed(42)\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from tensorflow.python.keras.applications import vgg16\n",
    "from tensorflow.python.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.python.keras import layers, models, Model, optimizers\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height, img_width = 64,64\n",
    "conv_base = vgg16.VGG16(weights='imagenet', include_top=False, pooling='max', input_shape = (img_width, img_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x00000180D74C1518> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000180D74C1E80> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000180DC849CF8> True\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x00000180DC899A58> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000180D7AA8748> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000180D99A0B70> True\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x00000180D99CAAC8> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000180D99CAB70> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000180D9A1EBE0> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000180D9A3F710> True\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x00000180D9A7AA20> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000180D9A7A320> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000180D9AC8B70> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000180D9AEDAC8> True\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x00000180D9B03630> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000180D9B262E8> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000180D9B7CF98> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000180D9B9C278> True\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x00000180D9BAD9B0> True\n",
      "<tensorflow.python.keras.layers.pooling.GlobalMaxPooling2D object at 0x00000180D9BD5080> True\n"
     ]
    }
   ],
   "source": [
    "for layer in conv_base.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 512)               14714688  \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 14,716,740\n",
      "Trainable params: 14,716,740\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Dense(4, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "learning_rate = 5e-5\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(lr=learning_rate, clipnorm = 1.), metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download Model\n",
    "label_class = {0:'BacterialPneumonia',\n",
    "               1:'COVID-19',\n",
    "               2:'Normal',\n",
    "               3:'ViralPneumonia'}\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras.preprocessing import image\n",
    "def load_image(img_path, show=True):\n",
    "\n",
    "    img = load_img(img_path, target_size=(64, 64))\n",
    "    img_tensor = img_to_array(img)                    # (height, width, channels)\n",
    "    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
    "    img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n",
    "\n",
    "    if show:\n",
    "        plt.imshow(img_tensor[0])                           \n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import os\n",
    "    import tkinter as tk\n",
    "    import tkinter.ttk as ttk\n",
    "    from tkinter import filedialog\n",
    "    from tkinter import * \n",
    "    from PIL import ImageTk,Image  \n",
    "except ImportError:\n",
    "    import Tkinter as tk\n",
    "    import ttk\n",
    "    import tkFileDialog as filedialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_open_image():\n",
    "    global rep\n",
    "    rep = filedialog.askopenfilenames(\n",
    "    \tparent=root,\n",
    "    \tinitialdir='/',\n",
    "    \tinitialfile='tmp',\n",
    "    \tfiletypes=[\n",
    "    \t\t(\"PNG\", \"*.png\"),\n",
    "    \t\t(\"JPEG\", \"*.jpg\"),\n",
    "    \t\t(\"All files\", \"*\")])\n",
    "    print(rep)\n",
    "    \n",
    "    global icon\n",
    "    image = Image.open(rep[0])\n",
    "    width, height = image.size\n",
    "    img = image.resize((round(250/height*width) , round(250)))\n",
    "    photo = ImageTk.PhotoImage(img)\n",
    "    icon.configure(image=photo)\n",
    "    icon.image = photo # keep a reference!\n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "def doMagic():\n",
    "    test_image = rep[0] #Input Image path\n",
    "    model.load_weights(\"sign_classifier_1.h5\") #Download and provide the Model path\n",
    "    new_image = load_image(test_image,False)\n",
    "    pred = model.predict(new_image)\n",
    "    #print(pred)\n",
    "    print(label_class[np.argmax(pred[0])]) #return\n",
    "    result[\"text\"] = label_class[np.argmax(pred[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('D:/uts/Semester 6 2020/Deep learning/Assignment 2/448.jpeg',)\n",
      "Normal\n",
      "('D:/uts/Semester 6 2020/Deep learning/Assignment 2/Xray.jpg',)\n",
      "COVID-19\n"
     ]
    }
   ],
   "source": [
    "root = tk.Tk()\n",
    "root.title(\"COVID-19 Classifier\") # Change the Title of the GUI\n",
    "root.geometry('600x400') # Set the size of the Windows\n",
    "title =ttk.Label(root,text =\"Welcome to Corona checking Lab\", font='Helvetica 18 bold')\n",
    "\n",
    "\n",
    "title.pack()\n",
    "\n",
    "xray = ttk.Label(root, text=\"Please upload your scan:\")\n",
    "xray.pack()\n",
    "\n",
    "uploadxray = ttk.Button(root, text=\"Open Xray\", command=c_open_image)\n",
    "uploadxray.pack()\n",
    "#canvas = Canvas(root, width = 300, height = 300)      \n",
    "#canvas.pack()      \n",
    "#img = ImageTk.PhotoImage(Image.open(\"Xray-icon.jpg\"))      \n",
    "#canvas.create_image(20, 20, anchor=NW, image=img) \n",
    "#photo = PhotoImage(file='Xray-icon.jpg')\n",
    "#cv = Label(master, image=photo)\n",
    "#cv.pack(side=BOTTOM)\n",
    "image = Image.open(\"Xray-icon.jpg\")\n",
    "width, height = image.size\n",
    "img = image.resize((round(250/height*width) , round(250)))\n",
    "photo = ImageTk.PhotoImage(img)\n",
    "icon = Label(image=photo)\n",
    "icon.image = photo # keep a reference!\n",
    "icon.pack()\n",
    "\n",
    "submit = ttk.Button(root, text =\"Check\")\n",
    "submit.pack()\n",
    "submit.config(command = doMagic)\n",
    "\n",
    "result = ttk.Label(root)\n",
    "result.pack()\n",
    "\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
