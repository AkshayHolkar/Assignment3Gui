{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "BhavanaVGGimage.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBPKsMEokmfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from numpy.random import seed\n",
        "seed(1337)\n",
        "#from tensorflow import set_random_seed\n",
        "#set_random_seed(42)\n",
        "from tensorflow.python.keras.applications import vgg16\n",
        "from tensorflow.python.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.python.keras import layers, models, Model, optimizers\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPq4V0BnkmfG",
        "colab_type": "text"
      },
      "source": [
        "# Number of categories\n",
        "## Images in each category"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3xJrFecQwg8",
        "colab_type": "code",
        "outputId": "6a735abb-fde5-41f8-c266-e9c55db5ab44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Lwu4_fBkmfH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_dir = r\"/content/gdrive/My Drive/TrainData\"\n",
        "test_data_dir = r\"/content/gdrive/My Drive/ValData\"\n",
        "\n",
        "category_names = sorted(os.listdir(train_data_dir))\n",
        "nb_categories = len(category_names)\n",
        "img_pr_cat = []\n",
        "\n",
        "for category in category_names:\n",
        "    folder = train_data_dir + '/' + category\n",
        "    img_pr_cat.append(len(os.listdir(folder)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKcoIGC0kmfK",
        "colab_type": "code",
        "outputId": "6d2f850e-a8fd-4974-d9c1-a3dd43a6bf13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "img_height, img_width = 64,64\n",
        "conv_base = vgg16.VGG16(weights='imagenet', include_top=False, pooling='max', input_shape = (img_width, img_height, 3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1cKubdQkmfN",
        "colab_type": "code",
        "outputId": "36417f20-6434-41b4-b871-77e1c3b1dbd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "for layer in conv_base.layers:\n",
        "    print(layer, layer.trainable)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7fa90a2c19e8> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa8bfe53908> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa8bfe74160> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fa8bf6338d0> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa8bf633748> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa8b05587b8> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fa8b055d0f0> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa8b055dac8> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa8b0567dd8> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa8b056e4a8> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fa8b05763c8> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa8b057dcf8> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa8b057de10> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa8b0584828> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fa8b0589550> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa8b0512c18> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa8b051a390> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa8b0521550> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fa8b0528438> True\n",
            "<tensorflow.python.keras.layers.pooling.GlobalMaxPooling2D object at 0x7fa8b05282e8> True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hsbi5vtQkmfQ",
        "colab_type": "code",
        "outputId": "d2719833-6055-452c-f334-759cf71993d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "  model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Dense(nb_categories, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 512)               14714688  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4)                 2052      \n",
            "=================================================================\n",
            "Total params: 14,716,740\n",
            "Trainable params: 14,716,740\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-hslAwNkmfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Number of images to load at each iteration\n",
        "batch_size = 32# only rescaling\n",
        "train_datagen =  ImageDataGenerator(rescale=1./255)\n",
        "test_datagen =  ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE7RBNO8kmfU",
        "colab_type": "code",
        "outputId": "8f6757a7-3d23-4994-d0fa-bf585df15f18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print('Total number of images for \"training\":')\n",
        "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
        "                                                    target_size = (img_height, img_width),\n",
        "                                                    batch_size = batch_size, \n",
        "                                                    class_mode = \"categorical\")\n",
        "\n",
        "print('Total number of images for \"testing\":')\n",
        "test_generator = test_datagen.flow_from_directory(test_data_dir,\n",
        "                                                    target_size = (img_height, img_width),\n",
        "                                                    batch_size = batch_size,\n",
        "                                                    class_mode = \"categorical\",\n",
        "                                                    shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of images for \"training\":\n",
            "Found 2083 images belonging to 4 classes.\n",
            "Total number of images for \"testing\":\n",
            "Found 988 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qjvAzswkmfX",
        "colab_type": "code",
        "outputId": "483a2726-f653-43f8-c867-114ba7598d30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "learning_rate = 5e-5\n",
        "epochs = 10\n",
        "checkpoint = ModelCheckpoint(\"sign_classifier_1.h5\", monitor = 'val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(lr=learning_rate, clipnorm = 1.), metrics = ['acc'])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QCOCe6fkmfZ",
        "colab_type": "code",
        "outputId": "90aee5f0-2224-49b4-bfb4-713ee8b8f0f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "source": [
        "history = model.fit_generator(train_generator, \n",
        "                              epochs=epochs, \n",
        "                              shuffle=True,\n",
        "                              validation_data=test_generator,\n",
        "                              callbacks=[checkpoint]\n",
        "                              )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-10-e75ae59a0785>:5: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/10\n",
            "66/66 [==============================] - ETA: 0s - loss: 0.8350 - acc: 0.6601 \n",
            "Epoch 00001: val_acc improved from -inf to 0.66599, saving model to sign_classifier_1.h5\n",
            "66/66 [==============================] - 1759s 27s/step - loss: 0.8350 - acc: 0.6601 - val_loss: 0.7842 - val_acc: 0.6660\n",
            "Epoch 2/10\n",
            "66/66 [==============================] - ETA: 0s - loss: 0.5470 - acc: 0.7614\n",
            "Epoch 00002: val_acc improved from 0.66599 to 0.79150, saving model to sign_classifier_1.h5\n",
            "66/66 [==============================] - 32s 481ms/step - loss: 0.5470 - acc: 0.7614 - val_loss: 0.5315 - val_acc: 0.7915\n",
            "Epoch 3/10\n",
            "66/66 [==============================] - ETA: 0s - loss: 0.4182 - acc: 0.8099\n",
            "Epoch 00003: val_acc improved from 0.79150 to 0.79453, saving model to sign_classifier_1.h5\n",
            "66/66 [==============================] - 32s 482ms/step - loss: 0.4182 - acc: 0.8099 - val_loss: 0.6277 - val_acc: 0.7945\n",
            "Epoch 4/10\n",
            "66/66 [==============================] - ETA: 0s - loss: 0.3550 - acc: 0.8493\n",
            "Epoch 00004: val_acc did not improve from 0.79453\n",
            "66/66 [==============================] - 31s 474ms/step - loss: 0.3550 - acc: 0.8493 - val_loss: 0.6158 - val_acc: 0.7338\n",
            "Epoch 5/10\n",
            "66/66 [==============================] - ETA: 0s - loss: 0.2868 - acc: 0.8805\n",
            "Epoch 00005: val_acc did not improve from 0.79453\n",
            "66/66 [==============================] - 31s 472ms/step - loss: 0.2868 - acc: 0.8805 - val_loss: 0.8621 - val_acc: 0.7743\n",
            "Epoch 6/10\n",
            "66/66 [==============================] - ETA: 0s - loss: 0.2021 - acc: 0.9141\n",
            "Epoch 00006: val_acc did not improve from 0.79453\n",
            "66/66 [==============================] - 31s 471ms/step - loss: 0.2021 - acc: 0.9141 - val_loss: 0.7563 - val_acc: 0.7844\n",
            "Epoch 7/10\n",
            "66/66 [==============================] - ETA: 0s - loss: 0.1644 - acc: 0.9342\n",
            "Epoch 00007: val_acc did not improve from 0.79453\n",
            "66/66 [==============================] - 31s 470ms/step - loss: 0.1644 - acc: 0.9342 - val_loss: 0.9430 - val_acc: 0.7642\n",
            "Epoch 8/10\n",
            "66/66 [==============================] - ETA: 0s - loss: 0.1106 - acc: 0.9558\n",
            "Epoch 00008: val_acc did not improve from 0.79453\n",
            "66/66 [==============================] - 31s 470ms/step - loss: 0.1106 - acc: 0.9558 - val_loss: 1.2811 - val_acc: 0.7510\n",
            "Epoch 9/10\n",
            "66/66 [==============================] - ETA: 0s - loss: 0.0898 - acc: 0.9645\n",
            "Epoch 00009: val_acc did not improve from 0.79453\n",
            "66/66 [==============================] - 31s 468ms/step - loss: 0.0898 - acc: 0.9645 - val_loss: 1.2617 - val_acc: 0.7702\n",
            "Epoch 10/10\n",
            "66/66 [==============================] - ETA: 0s - loss: 0.0683 - acc: 0.9712\n",
            "Epoch 00010: val_acc did not improve from 0.79453\n",
            "66/66 [==============================] - 31s 471ms/step - loss: 0.0683 - acc: 0.9712 - val_loss: 1.1165 - val_acc: 0.7743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-0sMCa0kmfb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.load_model(\"sign_classifier_1.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-KrNfCtkmfc",
        "colab_type": "code",
        "outputId": "ff31adad-0da4-4f8d-be49-390d5fbe87f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "Y_pred = model.predict_generator(test_generator)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-12-b1c17ed9393b>:1: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.predict, which supports generators.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHjYXiIGkmfe",
        "colab_type": "code",
        "outputId": "f54b0f74-72ae-4209-e248-0b5aed929fb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy = accuracy_score(test_generator.classes, y_pred)\n",
        "print(\"Accuracy in test set: %0.1f%% \" % (accuracy * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy in test set: 79.5% \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDNv_NYdkmfh",
        "colab_type": "code",
        "outputId": "7f4b01ce-f089-4dc0-e5db-8bf73a52debb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Download Model\n",
        "label_class = {0:'BacterialPneumonia',\n",
        "               1:'COVID-19',\n",
        "               2:'Normal',\n",
        "               3:'ViralPneumonia'}\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.python.keras.preprocessing import image\n",
        "def load_image(img_path, show=True):\n",
        "\n",
        "    img = image.load_img(img_path, target_size=(64, 64))\n",
        "    img_tensor = image.img_to_array(img)                    # (height, width, channels)\n",
        "    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
        "    img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n",
        "\n",
        "    if show:\n",
        "        plt.imshow(img_tensor[0])                           \n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "    return img_tensor\n",
        "\n",
        "test_image = r\"/content/gdrive/My Drive/TrainData/COVID-19/_0_1465610.jpeg\" #Input Image path\n",
        "model = models.load_model(\"sign_classifier_1.h5\") #Download and provide the Model path\n",
        "new_image = load_image(test_image,False)\n",
        "pred = model.predict(new_image)\n",
        "#print(pred)\n",
        "print(label_class[np.argmax(pred[0])]) #return"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "COVID-19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axmq_v3ET2wZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}